---
title: Ceph Days Berlin 2025
date: 2025-11-12
end: 2025-11-13
location: Berlin, Germany
venue: DESY, Platanenallee 6, 15738 Zeuthen
image: "/assets/bitmaps/ceph-days.png"
sponsors:
  - label:
    list:
      - name: Clyso
        logo: /assets/bitmaps/logo-clyso.png
tags:
  - ceph days
---

### Bringing Ceph to Berlin

A two-day event to share the transformative community and power of Ceph in Berlin

The first day offers interested parties, newcomers and non-technical people the opportunity to get to know about Ceph and the Ceph ecosystem.
The second day will focus on further promote Ceph learning.

## Important Dates

- **CFP Opens:** 2025-08-12
- **CFP Closes:** 2025-09-28
- **Speakers receive confirmation of acceptance:** 2025-10-03
- **Schedule Announcement:** 2025-10-15
- **Event Date:** 2025-11-12 to 2025-11-13

You can view the event schedule and venue details on the registration page. <a class="button" href="https://luma.com/217aro8t">Register Here!</a>

## Parallel Workshop on Day 1 (November 12th)

Ansgar Jazdzewski from Hetzner Cloud will host an additional session for attendees titled "Deep Dive & Hands-on Workshop in Ceph: Create Your Own Ceph-Test-System."

- **Location/Time**: Seminar Room 1. After lunch, starting at 14:30.
- **Requirements**: Attendees must bring their own laptops with Docker Container installed.
- **Capacity**: 15 people (applications accepted on a first-come, first-served basis).
- **Duration**: 60-90 minutes, including Q&A.
- **Registration Contacts**: [kristina.seel@clyso.com](mailto:kristina.seel@clyso.com), [roberto.vanoni@clyso.com](mailto:roberto.vanoni@clyso.com)


<style>
table {
  width: 100%;
  border-collapse: collapse;
  table-layout: fixed;
  word-wrap: break-word;
}
th, td {
  border: 1px solid #ddd;
  padding: 12px;
  vertical-align: top;
  text-align: left;
}
th {
  background-color: #f8f8f8;
  font-weight: bold;
}
td {
  white-space: normal;
}
tr:nth-child(even) {
  background-color: #f9f9f9;
}
</style>

### Day 1 — November 12, 2025
### Location: Seminar Room 3

<table>
  <thead>
    <tr>
      <th style="width: 6%;">Start</th>
      <th style="width: 18%;">Session Title</th>
      <th style="width: 30%;">Abstract</th>
      <th style="width: 10%;">Skill Level</th>
      <th style="width: 15%;">Speaker(s)</th>
      <th style="width: 21%;">Speaker Bio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>09:00</td>
      <td><strong>Registration &amp; Welcome Coffee</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>10:00</td>
      <td><strong>Welcome Session</strong></td>
      <td></td>
      <td></td>
      <td>Joachim Kraftmayer, CEO of Cylso and Geschäftsführer DESY</td>
      <td></td>
    </tr>
    <tr>
      <td>10:15</td>
      <td><strong>Morning Keynote: CephFS Home @ DESY</strong></td>
      <td>For many years, the Linux home directories at DESY were hosted on AFS. In November 2025 they were migrated to CephFS. This talk presents the CephFS architecture and details of the migration process.</td>
      <td>Beginner</td>
      <td><strong>Ingo Ebel</strong>, DevOps Science Engineer, DESY</td>
      <td>Ingo Ebel is an IT professional at DESY specialized in scalable storage architectures and open-source infrastructure. He actively contributes to the Ceph community (co-owner of the DFN Ceph discussion list). DESY will host the event location.</td>
    </tr>
    <tr>
      <td>10:50</td>
      <td><strong>Buzzword Bingo: Digital Sovereignty</strong></td>
      <td>Discover what digital sovereignty really means — and which low-hanging fruits can help you take the first steps toward it.</td>
      <td>Beginner</td>
      <td>
        <strong>Markus Wendland</strong>, Head of Customer Success, CLYSO GmbH<br>
        <strong>Heiko Krämer</strong>, Sales Representative, UhuruTec
      </td>
      <td>
        Markus Wendland is Head of Customer Success at Clyso, a committed open-source and Ceph evangelist, and member of the Sovereign Cloud Group.<br><br>
        Heiko Krämer is a Sales Representative at UhuruTec and active in the Sovereign Cloud Group; digital sovereignty is a core focus for him.
      </td>
    </tr>
    <tr>
      <td>11:25</td>
      <td><strong>SURFin' the Ceph Wave</strong></td>
      <td>
        <strong>Ceph in Practice:</strong> At SURF, the Dutch NREN, multiple on-prem services run on Ceph. Ceph has been in use at SURF for ~7 years; the estate includes 7 clusters (5 in production), some spread across datacentres, providing RBD, RGW and CephFS with ~280 physical machines, ~3600 OSDs, and ~40PB raw capacity.<br><br>
        This talk covers SURF's history, use cases, lessons learned, day-to-day operations, and future plans.
      </td>
      <td>Intermediate</td>
      <td><strong>Jean-Marie de Boer</strong>, Specialist, SURF</td>
      <td>IT-delivery specialist with 30 years of experience.</td>
    </tr>
    <tr>
      <td>11:35</td>
      <td><strong>Coffee Break 1 &amp; Networking</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>12:00</td>
      <td><strong>It's All About the Latency, Not the Bandwidth!</strong></td>
      <td>Latency is often misunderstood while bandwidth gets all the focus. This talk explains why latency is the key factor that should drive performance considerations.</td>
      <td>Intermediate</td>
      <td><strong>Wido den Hollander</strong>, CTO, Your.Online</td>
      <td>Wido has been part of the Ceph community for over 15 years. Formerly a Ceph consultant and trainer, he developed numerous features and remains active in the community in a new role.</td>
    </tr>
    <tr>
      <td>12:35</td>
      <td><strong>Running a Small OpenStack Cluster with a Full NVMe Ceph Cluster</strong></td>
      <td><strong>Ceph in Practice:</strong> In 2022 we embarked on a small adventure: running OpenStack backed entirely by a Ceph cluster with only NVMe drives. This talk shares our journey, challenges, and lessons learned.</td>
      <td>Any</td>
      <td><strong>Kevin Honka</strong>, CTO, AD IT Systems GmbH</td>
      <td>Kevin Honka is CTO, Senior System Engineer, and Consultant at AD IT Systems GmbH. With over 15 years in IT, he focuses on migrating from proprietary to open-source virtualization and automating operational workflows.</td>
    </tr>
    <tr>
      <td>13:05</td>
      <td><strong>Lunch Break &amp; Networking</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>14:30</td>
      <td><strong>Principles for Storage Management</strong></td>
      <td>
        Modern organizations generate data faster than legacy storage can handle. Ceph provides elasticity and control, but storage still needs to be treated as a business asset.  
        This talk explores four principles—Service Orientation, Architecture for Change, Data-Driven Operations, and Cost Transparency—to transition from reactive to product-oriented storage management.
      </td>
      <td>Beginner</td>
      <td><strong>Benedikt Bürk</strong>, Head of Professional Services, CLYSO GmbH</td>
      <td>Benedikt Bürk has 15+ years in real-time communications. He’s an expert in Enterprise Voice, Contact Center, and Omnichannel security solutions—from pre-sales design to implementation and support.</td>
    </tr>
    <tr>
      <td>15:05</td>
      <td><strong>VMware and Ceph: Virtualisation Meets Software-Defined Storage</strong></td>
      <td>Can Ceph deliver as a backend for VMware? This session explores Ceph block storage for VMs, both external and as a VSAN replacement. Includes setup, runtime behavior, and RBD mirroring for disaster recovery.</td>
      <td>Any</td>
      <td><strong>Victoria Mackie</strong>, Software Engineer, IBM</td>
      <td>Victoria is a UK-based software engineer with deep experience in enterprise block storage systems. After a decade working on IBM FlashSystem, she now focuses on VMware integrations for Ceph.</td>
    </tr>
    <tr>
      <td>15:40</td>
      <td><strong>Beyond Backup: S3 Data Management with Ceph RGW Tiering and Chorus</strong></td>
      <td>
        Learn how to manage S3 data in Ceph beyond backups using lifecycle policies to tier data between fast and low-cost storage, and restore efficiently.  
        The session also introduces <strong>Chorus</strong>, an open-source tool for large-scale S3 data movement and cutovers.
      </td>
      <td>Any</td>
      <td>
        <strong>Sirisha Guduru</strong>, Senior Cloud Engineer, CLYSO GmbH<br>
        <strong>Artem Torubarov</strong>, CLYSO GmbH
      </td>
      <td>
        Sirisha Guduru is a Senior Cloud Engineer at Clyso with experience managing multi-petabyte Ceph clusters in large-scale production.  
        Artem Torubarov is part of Clyso’s engineering team working on Ceph-based cloud infrastructure.
      </td>
    </tr>
    <tr>
      <td>16:10</td>
      <td><strong>Coffee Break 2 &amp; Networking</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>16:40</td>
      <td><strong>How RGW Stores S3 Objects in RADOS</strong></td>
      <td>Understand how radosgw stores S3 objects as RADOS objects across pools—what data is stored where and why. A foundational session to help with troubleshooting and design.</td>
      <td>Any</td>
      <td><strong>Tobias Brunnwieser</strong>, Infrastructure Engineer, Hetzner Cloud GmbH</td>
      <td>Tobias began as a C/C++ developer, later moving into infrastructure at a CDN/DDoS provider. Now at Hetzner, he builds S3-compatible storage with Ceph/RGW and focuses on large-scale orchestration and daemon internals.</td>
    </tr>
    <tr>
      <td>17:15</td>
      <td><strong>A Generic Ceph Sizer for the Community</strong></td>
      <td>A new open project to create a community-driven Ceph sizing tool that supports interactive design, workload optimization, hardware selection, and collaboration. Contributors welcome!</td>
      <td>Any</td>
      <td><strong>Matthias Münch</strong>, Principal Specialist Solution Architect, Red Hat</td>
      <td>Matthias has 30+ years in IT—from admin to presales specialist. Active in the Ceph community since 2016, he leads two German meetup groups and blogs about Ceph.</td>
    </tr>
    <tr>
      <td>17:30</td>
      <td><strong>AI, ML, and the Ceph Advantage: Scalable Storage for Smarter Workflows</strong></td>
      <td>This session explores how Ceph provides scalable, cost-effective, and high-performance storage for AI/ML workloads.</td>
      <td>Any</td>
      <td><strong>Kenneth Tan</strong>, Executive Director, Sardina Systems</td>
      <td>Dr. Kenneth Tan has 20+ years in large-scale systems, HPC, and cloud management. He leads Sardina Systems, focusing on sustainable data center operations and cloud economics.</td>
    </tr>
    <tr>
      <td>18:00</td>
      <td><strong>Networking Reception &amp; Food Truck</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>

---

### Day 2 — November 13, 2025
### Location: Seminar Room 3

<table>
  <thead>
    <tr>
      <th>Start</th>
      <th>Session Title</th>
      <th>Description</th>
      <th>Skill Level</th>
      <th>Speaker(s)</th>
      <th>Speaker Bio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>09:30</td>
      <td><strong>Welcome Coffee</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>10:00</td>
      <td><strong>Keynote: Focus on Object Storage in Transition</strong></td>
      <td>"The way we store and manage data is undergoing rapid change. At the heart of this evolution is Object Storage, which has transformed from a mere archiving solution into an essential foundation for modern cloud-native applications, big data analytics, and AI workloads.

This keynote examines the transformation of Object Storage and analyzes the current challenges—ranging from governance and security to scalability and cost control in hybrid and multi-cloud environments. 

Finally, the keynote provides an outlook on the Next Steps: What technological developments are on the horizon, and how can companies strategically leverage Object Storage to successfully drive their digital transformation and be prepared for the data deluge of the future."</td>
      <td>Intermediate</td>
      <td>Joachim Kraftmayer, CEO, CLYSO GmbH</td>
      <td>"Joachim Kraftmayer is the Founder and CEO of CLYSO GmbH, a leading specialist in open-source storage and multi-cloud strategies.

A recognized authority in Software-Defined Storage, Mr. Kraftmayer has a career spanning over 25 years in open-source technologies. He is an experienced Ceph expert, having worked hands-on with the technology for more than a decade. His passion for open-source solutions and their potential to deliver scalable, cost-efficient cloud architectures inspired his entrepreneurial path."</td>
    </tr>
    <tr>
      <td>10:35</td>
      <td><strong>Scale Multiple Ceph-clusters Horizontially</strong></td>
      <td>"Operating object storage at scale comes with unique challenges, especially when a single Ceph cluster reaches its practical growth limits. This talk explores strategies for scaling object storage horizontally by running multiple Ceph clusters in parallel while presenting a unified and transparent frontend to customers.

We will walk through how HAProxy can be configured to seamlessly route requests across different clusters, and how Ceph services need to be designed to support such an architecture.

The session will also cover real-world challenges encountered on the way"</td>
      <td>Advanced</td>
      <td>Ansgar Jazdzewski, Object Storage Engineer, Hetzner Cloud GmbH</td>
      <td>Ansgar Jazdzewski has over 10 years of experience working with Ceph in nearly every aspect of the ecosystem. For the past two years, he has been part of Hetzner Cloud as an Object Storage Engineer, where he is responsible for designing, building, and maintaining a cost-efficient, large-scale S3 object storage platform powered by Ceph.</td>
    </tr>
    <tr>
      <td>11:10</td>
      <td><strong>Building an AllNVme, six-data centre, ceph cluster</strong></td>
      <td>"Ceph in Practise: 
Hexion, which went into production in 2025, is a Cloud storage area network that is based on Ceph (Reef). Our design is unique in that we developed the cluster over a 40km fibre network consisting of six geo diverse data centres, using 8+4 EC to achieve the required fault tolerance. 
We can highlight the benefits and challenges of such a cluster, as well as the performance we have experienced in block and object storage."</td>
      <td>Intermediate</td>
      <td>"Stuart Hardy, Managing Director &
Zaid Bester, Hexion"</td>
      <td>I have been working in communication service provider infrastructure development for more than twenty-five years. I have been involved in the development of a wide range of infrastructure services, including Internet, MPLS, GPON, Application Optimisation, voice optimisation and SD WAN. I have spent twenty years in product management, and in that time I have started, scaled and exited three successful businesses. My latest business, Hexion, is based on Ceph.  </td>
    </tr>
    <tr>
      <td>11:20</td>
      <td><strong>Coffee break</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>11:45</td>
      <td><strong>The Need for Speed: Accelerating OpenStack with NVMe-oF & Ceph</strong></td>
      <td>"The quest for high throughput in OpenStack clouds often hits a bottleneck at the storage layer. This talk will explores how to break through this limitation. We’ll dive into NVMe-oF’s ability to deliver native NVMe performance over the network, surpassing the latency constraints of traditional SCSI-based protocols.

This session emphasizes how integrating Ceph as an external storage backend provides the scalability and performance needed to meet modern demands—enabling your OpenStack deployments (via Cinder and Nova) to support high-performance applications.

Attendees will gain both a conceptual foundation and a practical understanding of this powerful combination. The session culminates in a live demonstration showcasing key steps for integrating external Ceph storage with OpenStack, provisioning high-throughput NVMe-oF volumes, and attaching them to VMs. Join us for this session to take your OpenStack cloud to a new level and turn it into a serious data-processing engine."
      </td>
      <td>Intermediate</td>
      <td>Kritik Sachdeva, Technical Support Professional, IBM</td>
      <td>I’m Kritik Sachdeva, currently working as a Support Professional at IBM. I’ve been working with Ceph and OpenShift for the past three years, and my interest in technologies like Kubernetes, containers, cloud, Ceph, and automation started back in college.
    </td>
    </tr>
    <tr>
      <td>12:20</td>
      <td><strong>Speed up your deployments using the Ansible Cephadm colletion</strong></td>
      <td>This talk introduces an automated method of (re)deploying and setting up clusters quickly using an Ansible collection. It is a great way of integrating an existing Ansible managed environments (like OpenStack) with Ceph.
      </td>
      <td>Intermediate</td>
      <td>Piotr Parczewski, Senior Technical Lead, StackHPC Ltd.</td>
      <td>I help building custom Open Source powered clouds since 2016. 14 years overall IT industry experience, currently working with Ceph deployments of various sizes since 5+ years.
    </td>
    </tr>
    <tr>
      <td>12:35</td>
      <td><strong>Integrating Ceph RGW with Kubernetes: A Hands-On Demonstration of CSI-S3 Capabilities</strong></td>
      <td>"In this session, we will explore how to seamlessly integrate Ceph Object Gateway (RGW) with Kubernetes to enable scalable, cloud-native storage for modern workloads. Participants will get a hands-on walkthrough of configuring CSI-S3 capabilities, including:
walkthrough of configuring CSI-S3 capabilities, including:
- Enabling the CSI S3 driver
- Configuring the attacher and necessary components
- Creating StorageClasses for object storage
- Provisioning Persistent Volume Claims (PVCs)
- Deploying Pods that consume Ceph object storage

Through this practical demonstration, attendees will learn how to leverage Ceph RGW as a robust backend for Kubernetes workloads, enabling efficient, secure, and scalable object storage in cloud-native environments."
      </td>
      <td>Advanced</td>
      <td>Nilesh Chandekar, Technical Architects, Clear-Trail</td>
      <td>Nilesh Chandekar – With 13+ years of experience in OpenStack and Ceph, I had contributed to designing, deploying, and managing large-scale cloud infrastructures. I am an ex-Red Hatter and ex-racker engineer, currently driving sovereign cloud initiatives at ClearTrail, focusing on secure, scalable, and high-performance cloud solutions.
    </td>
    </tr>
    <tr>
      <td>13:05</td>
      <td><strong>Lunch Break</strong></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>14:30</td>
      <td><strong>Ceph-CSI Support for AES-GCM: Challenges and Opportunities</strong></td>
      <td></td>
      <td>Intermediate</td>
      <td>David Mohren, DephOps, CLYSO GmbH</td>
      <td></td>
    </tr>
    <tr>
    <td>14:45</td>
      <td><strong>To Diff or Not to Diff - Efficient Backups Using Server Access Logging</strong></td>
      <td>Backing up S3 data is often viewed as straightforward—just sync and go. However, examining how common backup tools actually implement this reveals significant hidden costs beyond the obvious storage requirements. Traditional tools like rclone perform continuous bucket listings and difference calculations to identify additions and deletions. For buckets containing tens or hundreds of millions of objects, this approach creates substantial system load and computational overhead, even when actual changes are minimal.
      </td>
      <td>Intermediate</td>
      <td>Yuval Lifshitz, Senior Technical Staff Memeber, IBM</td>
      <td>"Yuval Lifshitz works as a Senior Technical Staff Member at IBM. His current focus is enriching the Ceph ecosystem by adding server access logs, as well connectivity between the Rados Object Gateway and external message brokers (Kafka, Knative, RabbitMQ, etc.). He also added Lua scripting into the Rados Object Gateway to allow users customized behavior and more ecosystem interactions.
Yuval did public speaking in: Kubecon, Cephalocon, Open Source Summit, FOSDEM and local events."
    </td>
    </tr>
    <tr>
      <td>15:20</td>
      <td><strong>Faster CephFS Mirroring with Bounded-Frontier Concurrency</strong></td>
      <td>"cephfs-mirror today is largely single-threaded and, after a failover or restart, often rescans the entire remote tree. I’ll present two practical improvements:

1) Concurrent directory scanning + concurrent file transfer.
We use a bounded-frontier BFS↔DFS traversal where each directory is a task. When the global queue has capacity, we widen by enqueuing subdirectories (BFS); when it’s full, we dive (DFS) to keep making progress, continuously checking for newly freed queue slots to evenly distribute scan work across threads. In parallel, a second bounded queue feeds file-copy workers governed by in-flight byte limits. The result is adaptive parallelism, natural back-pressure, and predictable memory.

2) Snapshot-aware remote scanning on failover.
On restart or when a directory sync fails, the remote may be corrupted or only partially synced. In that case, we avoid a full remote rescan. We first reconcile against local snapshots to identify the matched tree and delta regions. Only the unmatched/delta parts are scanned and compared on the remote, and reconciliation runs only on those deltas. This shrinks recovery time and remote I/O while preserving correctness."
      </td>
      <td>Intermediate</td>
      <td>"Md Mahamudur Rahaman Sajib, Software Engineer, 
Croit GmbH"
      </td>
      <td>I’m Md Mahamudur Rahaman Sajib, a Software Engineer at Croit GmbH. I joined the Ceph upstream developer community in 2024, and my work focuses on CephFS internals, and C++ tooling.
    </td>
    </tr>
    <tr>
      <td>15:35</td>
      <td><strong>AI-Driven Certificate & Key Lifecycle Automation in Ceph Storage Compliance</strong></td>
      <td>Managing certificates and keys in Ceph is critical but often manual, complex, and error-prone. This talk introduces an AI-driven approach to certificate and key lifecycle automation, integrating with CAs and HSMs to enable secure, policy-driven, and autonomous management. Attendees will learn how agentic AI reduces operational overhead while enhancing compliance and resilience in Ceph environments.
      </td>
      <td>Advanced</td>
      <td>Harishkumar Bhokare, Lead Software Developer, IBM</td>
      <td><Agentic AI developer with expertise in Proxmox virtualization and Ceph distributed storage systems, specializing in designing intelligent automation for private cloud and hyperconverged infrastructures. Experienced in building self-managing clusters, developing AI-driven orchestration agents, and integrating storage intelligence with Proxmox VE for scalability, high availability, and cost-efficient operations. Skilled at combining infrastructure-as-code, observability pipelines, and LLM-powered decision systems to enable autonomous workload placement, healing, and scaling. Passionate about leveraging antigenic AI frameworks to reduce operational overhead, enhance storage resilience, and optimize performance across virtualized, containerized, and hybrid-cloud environments.
    /td>
    </tr>
    <tr>
      <td>16:00</td>
      <td><strong>Closing Remarks</strong></td>
      <td>Wrap-up and thank-you session, followed by informal networking.</td>
      <td></td>
      <td>DESY, Hetzner Cloud & CLYSO</td>
      <td></td>
    </tr>
  </tbody>
</table>

